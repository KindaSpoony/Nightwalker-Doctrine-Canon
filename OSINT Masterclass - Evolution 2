OSINT Collection Planning + Tradecraft with Case Studies (Masterclass Evolution 2)

Situation

Open-Source Intelligence (OSINT) has become a vital intelligence discipline across strategic, operational, and tactical levels. Modern conflicts (from Ukraine to counterinsurgencies) unfold on a digital terrain, requiring systematic OSINT planning. U.S. joint doctrine defines OSINT as information of intelligence value available to the general public, lawfully obtained by request, purchase, or observation ￼ ￼. OSINT complements classified sources by filling information gaps and providing context, but it is susceptible to adversary deception and bias, demanding rigorous tradecraft and validation ￼. In the current environment, massive public data (social media posts, satellite imagery, news, etc.) can be harvested – but must be filtered through planning frameworks and ethical constraints.

Frameworks for OSINT Planning: Established military planning tools guide OSINT targeting. Using METT-TC (Mission, Enemy, Terrain & Weather, Troops & Support, Time, Civil considerations), intelligence staffs incorporate OSINT into estimates:
	•	Mission: Identify what intelligence requirements (PIRs) the commander has – OSINT collection focuses on publicly available information that answers those PIRs (e.g. media reports about local threats or economic conditions affecting the mission).
	•	Enemy: Profile the adversary’s open-source footprint – enemy communications, social media usage, online propaganda, etc. OSINT targeting considers how the enemy uses the internet and what publicly observable indicators (training videos, forum posts, etc.) can be exploited.
	•	Terrain & Weather: Leverage open maps, GIS data, and meteorological databases. OSINT provides terrain analysis (e.g. open satellite maps) and weather forecasts to support Intelligence Preparation of the Battlespace (IPB). Civil terrain (human geography) is especially enriched by OSINT (population demographics, cultural sites, infrastructure data).
	•	Troops & Support: Assess friendly and partner forces’ OSINT needs and capabilities. OSINT can assist lower echelons lacking collection assets, and support force protection by scanning public info about friendly unit movements (for OPSEC). Also identify what local allies or coalition partners share on open networks.
	•	Time: Use OSINT tools to accelerate collection on short timelines (e.g. rapid news scraping during a crisis). If time is limited, focus on high-yield sources (local live reports, social media trends). For longer lead times, conduct deeper research (archived records, academic studies). Timing also affects update frequency – RSS feeds or alerts can provide continuous monitoring.
	•	Civil Considerations: OSINT is crucial for understanding the civilian environment – local sentiment, media narratives, humanitarian issues. It provides insight into population and propaganda factors of the battlespace ￼. This helps predict civilian behavior, identify key influencers, and gauge information operations (IO) effects. In IPB, OSINT plays an integral role in satisfying information requirements on population, culture, economics, and enemy information activities ￼ ￼.

Alignment with PIRs: OSINT collection must be driven by Priority Intelligence Requirements at each MAGTF echelon. For example, a Marine Expeditionary Unit (MEU) might set PIRs about local stability or terrorist threats during deployment – OSINT can monitor local news, social media chatter, and government releases to answer those PIRs. Higher echelons (MEF or Joint Task Force) have broader PIRs (e.g. adversary military movements, global reaction); OSINT contributes indications & warning by scanning international media, commercial satellite imagery, and trade data. At all levels, OSINT analysts map each PIR to potential open sources (e.g. maritime piracy PIR -> monitor shipping news and AIS vessel trackers). Intelligence Collection Plans should explicitly list OSINT as collection means next to SIGINT, HUMINT, etc., ensuring commanders receive a holistic view. Notably, OSINT often provides early warning and context: per JP 3-13 (Information Operations doctrine), open-source intelligence and internet newsgroups are valuable sources to measure operational effects and adversary influence ￼. Incorporating OSINT into the Intelligence Preparation of the Battlespace (IPB) process enriches every step – from defining the environment (using public data on terrain and society), to describing effects (crowdsourced maps of weather/terrain impacts), evaluating the threat (mining enemy propaganda and order of battle data from open sources), and determining threat COAs (analyzing online chatter for likely actions). Doctrine emphasizes that publicly available information, when properly integrated, can satisfy many intelligence needs identified in the planning process ￼.

Sidebar – Intelligence Oversight: All OSINT activities must comply with U.S. laws and policy (EO 12333, DoD 5240.01) regarding collection on U.S. persons and privacy. Even though OSINT uses public information, intelligence units must obtain and use it under the same ethical and legal constraints as any intel. For example, collecting social media posts of U.S. civilians requires adherence to intelligence oversight rules (e.g. DoD Manual 5240.01 procedures). OSINT operations are planned with legal review to ensure they don’t stray into unauthorized surveillance. VAULTIS data principles – Visible, Accessible, Understandable, Linked, Trustworthy, Interoperable, Secure – are upheld in all OSINT handling ￼ ￼. This means OSINT sources and methods are made visible and appropriately classified for oversight, data is shared on approved systems (accessible & interoperable), context is documented (understandable, linked), source reliability is vetted (trustworthy), and sensitive data (including personal information) is protected (secure). These principles guide ethical OSINT exploitation in every phase.

In summary, the situation is one of expanding OSINT opportunities across the MAGTF and joint force, requiring structured planning (using METT-TC and IPB frameworks) to focus collection on commander’s needs, while rigorously managing the risks and ethics of using public information in military intelligence.

Mission

Mission Statement: The MAGTF (or training audience) will conduct OSINT collection planning and execute open-source intelligence tradecraft in support of commander’s PIRs, integrating OSINT into the intelligence cycle to enhance situational awareness and decision-making. We will apply METT-TC and IPB frameworks to identify OSINT targets, employ passive collection Tactics, Techniques, and Procedures (TTPs), and exploit case study lessons (MH17, Marawi, Ukraine 2022) to demonstrate how public data can shape operations. Endstate: Students (or units) understand how to build an OSINT collection plan aligned with mission requirements, practice safe and ethical OSINT tradecraft, and appreciate historical examples where OSINT influenced tactical and strategic outcomes. This will be achieved in accordance with doctrinal guidelines (JP 2-0, JP 3-13, MCDP-2, ATP 2-22.9, NATO OSINT Handbook, ODNI best practices) and upholding VAULTIS principles throughout the operation.

Execution

Commander’s Intent: Exploit publicly available information to the fullest extent to support the mission, without compromising security or ethics. OSINT operations will be passive, thorough, and fused with all-source intel. We will leverage advanced web search and social media monitoring to gather relevant data, maintaining covertness (no active engagement with targets online) and ensuring accuracy through cross-verification. Case studies will be used to illustrate successful OSINT integration and to train analysts in recognizing where and how to inject OSINT findings into the decision cycle. Success is defined by OSINT indicators answering PIRs, timely dissemination of verified OSINT to commanders, and all actions compliant with oversight and doctrine.

Concept of Operations: We will proceed in three phases: (1) Planning & Preparation – Identify PIRs and OSINT requirements using METT-TC/IPB; assign research tasks and set up passive collection channels. (2) Collection & Analysis – Employ passive TTPs (detailed below) to gather data; analyze and fuse OSINT into intelligence products with proper sourcing. (3) Dissemination & Integration – Inject OSINT findings at key decision points (as shown in case studies), informing operations, while conducting continuous ethical risk assessment (using scenario-based drills).

Passive Collection TTPs: All collectors will use passive techniques that do not alert the adversary or violate terms of service. Key TTPs include:
	•	Advanced Web Search (“Google Dorking”): Utilize specialized search operators to pinpoint information. For example, use site: to search within a specific domain, filetype: to find leaked documents, and other Boolean operators. Google dorking allows analysts to narrow search results to exactly what is needed, uncovering hidden pages or files ￼. This technique can reveal cached pages, directory listings, or forgotten PDFs relevant to the mission. Analysts will employ a curated list of search strings (from ATP 2-22.9 Appendix C) to find specific data (e.g. using intitle:"equipment list" or intext:"restricted" plus keywords to find potentially useful open data). Note: These searches are done on unclassified networks and only on publicly accessible data – no hacking or credentials required (ensuring activities remain within “publicly available” bounds).
	•	RSS Feeds & Web Monitoring: Set up RSS feeds and alerts for relevant websites and news sources. Rather than manually checking dozens of sites, we aggregate updates into feed readers. For example, if monitoring a local news site or a terrorist group’s blog, an RSS feed can tip us off immediately to new posts. We will also use change-detection tools on key web pages (to catch edits or deletions). This feed mapping allows continuous, passive collection – essentially creating a “digital early warning system” for our PIRs. If a target website lacks RSS, analysts might use open-source tools to scrape updates (within allowed policies). All retrieved content will be logged with date/time for timeline analysis.
	•	Social Media Forensics: Exploit social media platforms to gather intelligence on adversaries and environments. This includes passively observing Twitter (X), Facebook, Instagram, Telegram, YouTube, and regional platforms for relevant chatter, photos, or videos. Techniques: Use keyword and hashtag searches, follow known accounts (covertly, without engaging), and utilize tools like TweetDeck (now X Pro) to monitor multiple streams in real-time. TweetDeck allows an investigator to view several filtered feeds (by hashtag, user, keyword, etc.) in one dashboard ￼, which is invaluable during fast-moving events (e.g. protests, battles) for situational awareness. We will set up TweetDeck columns for key terms (e.g. location names, event-specific hashtags) and for lists of local reporters or observers. Social media forensics also involves verifying content: analysts will examine images/videos for metadata, geolocation, and signs of manipulation. For instance, an image’s shadows and landmarks can be compared with maps to confirm location (a tradecraft Bellingcat famously used in the MH17 case). All findings are cross-checked (e.g. the same event reported by multiple independent users) to ensure trustworthiness. We remain strictly passive – no “friending” targets or sock-puppet engagement (which could violate terms or tip off adversaries).
	•	OSINT OPSEC: Throughout collection, we practice strict Operational Security. Analysts use secure browsers and alias accounts that do not reveal DOD/IC affiliation (per ODNI best practices) when accessing forums or social media. We avoid logging into personal accounts or interacting with sources. If deeper access is needed (e.g. closed groups), we seek guidance – but by default this training focuses on information obtainable without any overt collection. All queries and downloads are done in ways that minimize our digital footprint (e.g. using VPNs or the Tor network when appropriate and authorized, to avoid attribution to U.S. military networks). Passive collection means looking and not touching – we treat the internet like a jungle observation post: watch everything, disturb nothing.

Tradecraft and Analysis: Once collected, OSINT data is processed and analyzed like any intel – source reliability and content credibility are rated ￼, information is corroborated with other sources (ideally, OSINT is fused with SIGINT/HUMINT to build all-source assessments). Analysts will annotate timelines and maps with OSINT findings to visualize how information flows impact operations (as shown in case studies). Notably, OSINT requires careful source vetting: adversaries may plant false information openly. Our tradecraft drills analysts to detect propaganda or deepfakes (e.g. verifying images via reverse image search, checking timestamps, consulting multiple independent outlets). We also maintain detailed citations for all OSINT used – following ODNI citation standards for Publicly Available Information (PAI) – to enable discoverability and transparency ￼. (For example, if we use a YouTube video as evidence, our report will cite the video ID, uploader, date, and any archive link, so it can be reviewed by others. This aligns with the VAULTIS “Visible” and “Understandable” principles.)

Case Studies (OSINT Injection Points): To illustrate Execution, we examine three historical cases – MH17 (2014), Battle of Marawi (2017), and Russia-Ukraine War (2022) – highlighting how OSINT was collected and injected, and how public data shaped decisions or narratives. Each case study includes an annotated timeline or map of key OSINT events:

Figure: Comparative analysis of a Russian Buk missile launcher – left image from a June 2014 Russian convoy, right image from July 17, 2014 in Ukraine. Red circles highlight identical markings. OSINT analysts matched these images to conclude the Buk that downed MH17 came from Russia’s 53rd Brigade ￼.
	•	Case Study 1 – MH17 (2014): In July 2014, Malaysia Airlines flight MH17 was shot down over eastern Ukraine. OSINT played a decisive role in tracing responsibility. Within hours of the crash, public data started emerging: local civilians posted photos of smoke in the sky and wreckage; Russian-backed militants inadvertently posted (and deleted) a boast about downing a “bird”. OSINT analysts worldwide, notably the collective Bellingcat, began scouring social media for clues. They tracked a Buk surface-to-air missile system in separatist territory through a series of publicly shared images/videos. For instance, at 10:45 on July 17, a civilian’s photo showed a Buk launcher on a transport truck leaving Donetsk ￼. Between 11:00–12:45, multiple sightings (shared via VKontakte and Twitter) placed the launcher in towns along the H21 road (Zuhres, Shakhtarsk, Torez) ￼. By 13:30, a video (uploaded to YouTube) from Snizhne showed the Buk being unloaded from its truck and moving south under its own power ￼. At 16:20, MH17 was shot down – and locals’ frantic posts of a mid-air explosion and debris confirmed the event ￼. OSINT analysts geolocated each photo and video: by matching landmarks in the images (buildings, billboards, terrain) with Google Street View and satellite maps, they pinpointed exact locations of the Buk at specific times ￼. They even noted the absence of one missile in a later video, indicating it had been fired. Using shadow analysis and timestamps, Bellingcat built a precise timeline of the Buk’s journey ￼. Crucially, they identified distinguishing markings on the Buk launcher – such as a partial serial number and unique white marks (circled in the figure above) – and matched these to Russian military unit 53rd Anti-Aircraft Brigade from Kursk ￼. This was done by finding photos on Russian social media of that unit’s convoy weeks earlier, showing the same vehicle. OSINT also included intercepted phone calls released by Ukraine, but the publicly available images were the smoking gun. The outcome: OSINT findings were shared widely and with official investigators – the Dutch-led Joint Investigation Team later validated Bellingcat’s OSINT evidence and indicted Russian personnel ￼. This case demonstrates OSINT’s power: public data shaped the global narrative (Russia’s denials were undermined by open evidence) and informed diplomatic and legal actions. It also showcased tradecraft: volunteers using passive collection (scraping VK pages, YouTube, archives of deleted posts) and rigorous analysis (geolocation, chronolocation, crowdsourced verification ￼). Injection points in MH17 were at nearly real-time: OSINT alerts (social media reports) informed intelligence analysts the moment the shootdown happened, and within days OSINT provided key investigative leads that shaped the course of the inquiry and international response.

Figure: Devastated downtown Marawi (October 2017) after five months of fighting. Public imagery of the destruction – like this Reuters photo – and militant propaganda videos were key OSINT inputs during and after the battle ￼.
	•	Case Study 2 – Battle of Marawi (2017): During the urban battle in Marawi City, Philippines (May–October 2017), OSINT served both operational and informational roles. The siege began when ISIS-affiliated militants seized the city. Public social media quickly became a battleground: militants posted propaganda (via ISIS channels like Amaq Agency) to project strength, while civilians trapped in the city used Facebook and SMS to plea for help, and local journalists reported via Twitter. One pivotal OSINT event was an Islamic State video showing the destruction of a Catholic church in Marawi, released in June 2017 ￼. This video, which was geolocated to a church in the combat zone, had strategic effects: it inflamed religious tensions, rallied extremist supporters online, and forced the Philippine government to counter ISIS’s narrative of establishing a “wilayah” (province). Intelligence analysts collected such videos and extracted clues – e.g. backgrounds in the footage helped map militant positions, timestamps indicated when certain areas were overrun. Security forces, with U.S. advising, monitored militants’ digital communications (Telegram chats, extremist forums) to gauge if they were receiving outside support – an OSINT task since much of that chatter was in public or semi-public online groups. OSINT also helped identify foreign fighters: researchers noted militant social media accounts from Malaysia, Indonesia, etc. boasting about joining the Marawi battle, giving indications of the multi-national nature of the insurgency (information later confirmed by captured documents). On the defensive side, Filipino citizens on social media voiced grievances about the destruction; these OSINT insights into public sentiment influenced how the government messaged its post-battle reconstruction plans. Timeline injection: In the early hours of the siege (23 May 2017), locals’ tweets and Facebook Live videos warned of armed men setting up roadblocks – likely the first “intel” the wider world got of the attack. Mid-battle, as civilian evacuations occurred, open-source photos of humanitarian conditions (e.g. crowded evacuee camps) alerted planners to potential crises, shaping logistics and aid (an example of OSINT informing civil-military operations). After the battle ended in October, satellite images and drone footage of Marawi’s ruins (released via media) quantified the destruction, impacting both domestic opinion and foreign aid decisions. OSINT shaped narratives: Amnesty International’s open-source based report on Marawi’s “trail of death and destruction” (citing eyewitness videos and images) pressured the Philippine government on human rights compliance. Thus, OSINT in Marawi was not just collection for targeting, but a feedback mechanism for oversight and strategic communications. It also raised an ethical dimension: much of the OSINT came from the “domestic digital terrain” – Filipino citizens’ communications. This forced Philippine and U.S. intelligence advisors to navigate laws about monitoring domestic social media, foreshadowing our Ethical Scenarios (e.g. how to handle information on U.S. persons or allies found online). The case underlines that public narratives can be as critical as bullets – and OSINT practitioners must be adept at both exploiting and countering information in the open domain.

Figure: Satellite imagery (Planet Labs) of Russian troop buildup in Yelnya, Russia, Feb 2022 – a commercially available image used by OSINT analysts to warn of the impending Ukraine invasion ￼.
	•	Case Study 3 – Russia-Ukraine War (2022): The full-scale invasion of Ukraine in February 2022 is sometimes dubbed the “OSINT War” due to the unprecedented volume of open-source intelligence employed. In the lead-up to the war, OSINT indicators sounded alarms well before some governments did: commercial satellite images (like the Planet Labs photo above) showed massive Russian force concentrations near Ukraine’s borders ￼ ￼. OSINT analysts (from investigative outlets and the intelligence community) published these images and analyses on Twitter and news blogs, shaping global perception and enabling allied decision-makers to prepare (the U.S. and UK governments even cited open satellite imagery to build international consensus of the threat). When the war began, real-time OSINT became integral at the tactical level – Ukrainians and volunteer analysts worldwide scraped social media for videos of troop movements, intercepted unencrypted radio communications on apps, and tracked equipment losses through geotagged photos. For example, TikTok videos posted by locals inadvertently revealed a Russian armored column’s location, which Ukrainian forces used to coordinate an ambush (a reported incident early in the war). Throughout the conflict, numerous OSINT injection points have influenced operations: open-source analysts helped identify and locate targets (like the exact location of a stranded Russian naval vessel discovered via Instagram posts), and conversely, exposed Russian misdeeds (e.g. verifying war crime scenes). A dedicated OSINT coalition effort, the “Eyes on Russia” project, mapped over 23,000 incidents of strikes and movements on an interactive public map ￼ – data later used by prosecutors for war crimes evidence. OSINT also played a role in information warfare: analysts debunked Russian disinformation by comparing claims to open evidence (for instance, when Russia tried to deny responsibility for civilian casualties, OSINT investigators provided timestamped video and satellite proof of Russian shelling). The timeline of the invasion’s first weeks is studded with OSINT: Day 1 saw live webcams and Twitter videos documenting the assault on Hostomel Airport; Week 2 had NGO-sponsored satellite images of a 40-mile convoy north of Kyiv which alerted Ukrainian defense to its presence. As another facet, Ukraine’s government actively solicited OSINT from citizens – they launched a Telegram bot for civilians to report enemy sightings (blurring the line between citizen and intelligence source in a novel way). Publicly available sensor data, like flight tracking sites for aircraft or ship location databases for naval movements, also became part of the OSINT toolkit feeding into operations. Strategic impact: OSINT has proven “crucial to expose potential war crimes from afar and support accountability efforts” ￼ ￼ – for example, Bellingcat and others verified and catalogued atrocities (such as the Bucha massacre) via publicly shared videos, influencing international justice and policy (several countries cited these OSINT findings to justify expulsions of diplomats and increasing sanctions). In sum, the Ukraine case demonstrates a mature integration of OSINT: military commands now openly acknowledge using OSINT alongside classified intel for timely understanding of the battlefield. It also highlights coalition sharing: NATO and partner nations had to rapidly share OSINT findings (like satellite imagery analysis) at unclassified levels to coordinate their responses, a process that tested policies on intelligence disclosure. The Ukraine experience cemented OSINT’s legitimacy – as one Ukrainian investigator noted, the war showed that digital investigation techniques became the primary form of information collection and verification in the conflict ￼ ￼.

Each case study above underscores how public information can shape tactical decisions and strategic narratives. The injection points – whether it’s a tweet forewarning an ambush or a satellite image validating an intel report – show that commanders and analysts must be prepared to consume OSINT rapidly and thoughtfully. These cases will be debriefed in class, with emphasis on how OSINT was obtained, validated, and used, and what could be improved (e.g. in MH17, OSINT was reactive – future OSINT could proactively flag such missile movements; in Ukraine, managing OSINT flood is a challenge).

Ethical Scenario Drills: To reinforce tradecraft and oversight, we now engage in branching decision scenarios. Each scenario presents an OSINT ethical dilemma with 2–3 possible actions. We will discuss outcomes for each choice, including tactical implications (mission impact), oversight compliance considerations, and a doctrinal debrief linking to policies (JP, laws, etc.). These are designed for group discussion – instructors will guide you through each branch. (Each scenario is tagged Scenario 1, 2, 3 for easy reference.)

Scenario 1: Domestic Digital Surveillance Dilemma – Situation: You are an intelligence analyst at a MEF in the U.S., tasked to monitor potential security threats during a stateside disaster response (e.g. a hurricane relief operation). On public social media, a local extremist group is organizing violent protests that could target military relief convoys. The group’s leaders are U.S. persons using Facebook and Twitter openly. Intelligence Oversight Question: How do you collect and report this information?
	•	Option A: Actively monitor and archive the group’s social media posts (which are public), and include detailed information about the individuals in an intelligence report for the command. Implications: Tactically, this provides commanders with early warning of protests or attacks, possibly safeguarding the convoy route. However, oversight compliance: this veers into collecting intelligence on U.S. persons – even though the info is public, DoD intelligence components must follow procedures (per EO 12333 and DoDM 5240.01) before retaining U.S. person information. Simply archiving their posts might violate policy unless an exemption (like “Force Protection” or law enforcement coordination) is invoked and approved. The analyst would need legal guidance and perhaps involve civilian law enforcement (since this crosses into domestic surveillance). If done improperly, it risks oversight violations and public trust issues if revealed. Doctrinal Debrief: JP 2-0 and DoD directives stress that intelligence activities involving U.S. persons require strict adherence to legal frameworks – even OSINT isn’t free from this ￼ ￼. The correct doctrinal approach would be to hand off lead responsibility to law enforcement or an authorized agency, or get proper authorization and review (through the chain of command and legal) to continue. Outcome A might achieve security in the short term but could breach intelligence oversight rules, which is unacceptable doctrinally.
	•	Option B: Notify and coordinate with law enforcement or a fusion center, but do not directly collect/store detailed personal data from the group’s posts. Instead, limit your reporting to general threat indicators (e.g. “public calls for protest at X location”) without naming U.S. individuals, and ensure any further monitoring is done under civilian authority. Implications: Tactically, this means the command gets less granular intel (perhaps just a warning of possible unrest), and response may be slower or less tailored. But it protects the military unit from stepping over legal lines. Oversight compliance: This choice adheres to the principle that DoD intelligence elements should not target U.S. persons unless absolutely necessary for mission and with approval. By passing the info to law enforcement, you leverage the proper channels (since domestic intelligence mainly lies with FBI/DHS). You also classify your report appropriately (perhaps as “For Official Use Only” since it involves sensitive personal data) and mark that information was derived from social media (ensuring transparency). Doctrinal Debrief: This aligns with JP 2-0’s guidance that intelligence support to civil authorities must be done in accordance with laws and usually in support, not lead, roles. It demonstrates VAULTIS “Trustworthy & Secure” handling – you respected privacy and kept the data secure, maintaining public trust. The downside is if law enforcement fails to act timely, the unit might be caught off-guard – but doctrinally, that risk is weighed against the absolute requirement to obey U.S. law. Outcome B is compliant and in line with VAULTIS ethics, though possibly at some cost to immediacy of intelligence. A potential middle ground doctrinally is requesting an exception/approval through your command’s Staff Judge Advocate and the Designated Approving Authority for intel oversight – but that takes time and must be justified by a serious threat.

(Debrief: In classroom discussion, we’d emphasize that the best practice per ODNI and DoD OSINT guidelines is to never casually collect on U.S. persons, even if info is public. Always involve legal early. Outcome B likely would be deemed the correct action in a training environment.)

Scenario 2: Ambiguous Source Leak – Situation: During an overseas operation, you discover a dump of documents on an online forum (Pastebin) claiming to be leaked enemy communications. It’s not password-protected – anyone can download. The content could hugely inform your targeting (it lists insurgent safe houses), but you cannot verify if it’s authentic or if it was obtained legally. It might even contain malware. What do you do?
	•	Option A: Download and exploit the files immediately, treating them as open-source since they were openly posted, to get whatever intel they contain. Implications: If the docs are real, you gain valuable target intelligence quickly – perhaps preventing an ambush or locating high-value individuals. However, oversight compliance: there’s a risk these documents were obtained by illicit hacking (violating privacy or even containing classified info inadvertently). Using them might be legally problematic (e.g. if the U.S. military is seen as benefiting from a criminal cyber intrusion). There’s also security risk – the files could have embedded spyware targeting defense users. DoD policy (ATP 2-22.9 Appendix A) would caution that just because something is online doesn’t automatically make it “fair game”; certain data (like hacked materials) can be off-limits or require higher approval. Additionally, disseminating unverified info could lead to false actions (imagine if it’s deception by the enemy – a real possibility in OSINT, as adversaries deliberately plant false data ￼). Doctrinal Debrief: Intelligence doctrine says information must be evaluated for reliability – jumping on unvetted leaks fails that test. Also, ODNI best practice is to ensure sourcing and legality: IC standards (ICS 206-01) emphasize only using OSINT that can be properly cited and retained ￼. Outcome A might violate those by ingesting dubious data.
	•	Option B: Pause and vet the source, and seek guidance. You would run antivirus on the files in a secure sandbox, perform a quick authenticity check (do bits of it match known intel?), and notify your chain of command and S-2/XO that you have a potential source of information of uncertain providence. You might involve CI (counterintel) to ensure it’s not enemy malware bait. Only after legal and CI clearance do you utilize the info, and even then with caveats. Implications: Slower – you might lose some actionable immediacy. But tactically, you avoid possible traps (disinfo or malware) that could cripple your systems or mislead your unit. Oversight compliance: Strong – you treated the data responsibly, ensured using it doesn’t break any laws or policy. If higher approves its use, you’ll also mark the intelligence product appropriately (likely source description like “Possible PAI obtained from unknown online user”) to maintain transparency for decision-makers ￼. Doctrinal Debrief: This follows the intelligence cycle properly – collection (you found something) is followed by processing (safe handling) and evaluation before exploitation. It reflects JP 2-0’s guidance to consider adversary deception in OSINT ￼ – by not trusting it blindly. It also aligns with VAULTIS “Trustworthy” principle – ensuring data integrity and truth before action. Outcome B demonstrates discipline: in operations, acting on bad info can be worse than having no info. Doctrine would support the cautious, vetted approach, even if that means potentially missing a fleeting opportunity. (In discussion, we’d note if it were extremely high stakes – e.g. imminent threat – commanders might decide differently, but they’d do so consciously, weighing the risks.)

Scenario 3: Coalition Sharing Constraints – Situation: You are the OSINT officer in a combined joint task force with NATO partners. You’ve used a U.S.-only OSINT tool that scrapes Twitter for specific geo-tagged data, and you discovered critical information about an impending attack in your ally’s sector. However, the tool and dataset are Not Releasable To Foreign Nationals (NOFORN) by policy, because it involves licensed proprietary data and some U.S.-only techniques. The ally’s forces are in danger if they don’t get this intel promptly. How do you proceed?
	•	Option A: Share the intelligence with the coalition partner immediately (e.g. verbally or in a sanitized brief), without revealing the sensitive tool or exact source. Essentially, you’d pass the “what” (the warning) but hide the “how”. Implications: This could save lives – the ally is alerted and can act. It fosters coalition trust in the moment. But oversight compliance: you might be violating classification rules or data-use agreements. If the OSINT tool’s output is considered U.S. proprietary or if it included data that can’t be shared (perhaps it combined social media data with a U.S. database), sharing even the substance could breach agreements or law (similar to exposing sources/methods). Additionally, by not revealing how you know, the ally might question the intel’s reliability or be unable to integrate it fully (they may have follow-up questions you can’t answer without compromising sources). Doctrinal Debrief: Foreign Disclosure regulations (and JP 2-0 guidance on intelligence sharing) require that any intel shared with partners goes through a disclosure authority (FDO) who vets that sources/methods are protected ￼. By skipping that, you as an OSINT officer are exceeding authority. JP 2-0 explicitly notes OSINT products and sharing must be approved by the appropriate Foreign Disclosure Officer (FDO) and follow guidance ￼. Outcome A, while well-intentioned, breaks doctrinal procedure and could risk the program or future sharing if discovered.
	•	Option B: Initiate an urgent foreign disclosure request through the chain of command, attempting to rapidly sanitize the intel so it can be shared properly. You might also use alternative pathways: for instance, guide the ally to collect the info themselves (“You may want to check Twitter for posts around coordinates X at time Y”) without directly handing them the U.S.-collected product. This way, they get the info from open sources on their own, which is generally allowable. Implications: There’s a delay as bureaucracy catches up – possibly the difference between success or failure of their mission if time is very short. However, tactically you still transfer knowledge in a cooperative but legal way (especially by hinting at open data they themselves can grab – essentially enabling them to do their own OSINT). Oversight compliance: High – you respected policy, involving the FDO and only sharing what’s authorized. Policy might let you share the “essence” but not the raw data or tool output. Doctrinal Debrief: This follows NATO and DoD best practices for OSINT: share finished intelligence or sanitized reports rather than raw feeds, when tools are sensitive. It leverages the fact that OSINT is unclassified by nature – if the critical information is truly from Twitter, theoretically anyone (including the ally) could get it. So by pointing them to it, you aren’t violating rules. You are also fulfilling the spirit of coalition intel sharing – unity of effort – without breaking trust with data providers or higher HQ. JP 2-0 and NATO doctrine encourage maximum sharing consistent with security; your actions align with that, using creativity (directing them to PAI) to get around red tape. Outcome B is doctrinally sound, though it tests our agility. (Classroom note: if time was so critical that formal disclosure would be too slow, this scenario sparks discussion on commanders’ risk decisions – perhaps a commander might choose to share and accept responsibility later. But as an analyst, the correct procedure is to seek disclosure clearance or enable partner collection.)

These scenarios reinforce that ethical decision-making in OSINT is as important as technical skill. By examining outcomes, students see that shortcuts can undermine the mission in the long run (through legal trouble or loss of trust), and that adhering to doctrine (while perhaps slower) preserves the integrity of intelligence operations. The tactical implications, compliance analysis, and doctrinal references in each outcome link back to our core lesson: effective OSINT support requires balancing aggressiveness in collection with restraint in line with law and policy.

(Facilitation note: During execution, each scenario can be discussed in groups, with trainees justifying which option they’d choose and an instructor guiding them to doctrinally correct answers. VAULTIS principles – e.g. the need for data to be Linked, Accessible, Interoperable but also Secure and Trustworthy – should be explicitly noted in their reasoning.)

Admin & Logistics

Resources & Tools: The following OSINT tools and platforms are available/in scope for this training (with notes on capabilities, usage, and policy status):
	•	Maltego: A powerful link-analysis platform that mines open data (e.g. DNS records, social networks, “people search” info) and visually maps relationships. Capability: Maltego can quickly pivot through disparate data sources – for example, starting from an email address it can find associated social media profiles, breaches, domain ownership, etc., building a graph of entities. This is useful in mapping insurgent networks or supply chains from open info. Training Applicability: We will use Maltego in a lab to practice uncovering an alias used by a threat actor and mapping their connections. It’s user-friendly but requires an analytical mindset to configure “transforms” (pre-built queries). Policy/Approval: DoD Usage: Maltego is a commercial tool; it’s not an official program of record in most DoD units, but it’s widely used in demonstrations and by specialized teams. Its use of public data is fine on unclassified systems – however, analysts must not input classified or sensitive (e.g. PII of U.S. persons) as search queries without authorization. Also, Maltego’s use of certain transforms (like querying social media APIs) may be limited by those services’ terms. In our setting, Maltego is for training and illustrative use. (Some IC agencies have similar link analysis tools on classified networks – the concepts transfer, but Maltego itself should be considered unclassified illustrative tool, not currently on JWICS/SIPR by default.) According to a Defense OSINT strategy report, tools like Maltego can help standardize Army OSINT processes, but require proper procurement and oversight ￼. We treat Maltego as authorized on our training network only, and any real-world use would go through tech approval.
	•	TweetDeck / X-Pro: A social media dashboard (owned by Twitter/X) that allows monitoring multiple feeds and advanced searches in parallel. Capability: TweetDeck is excellent for real-time monitoring – one column might track a hashtag (#BattleOfMarawi), another a user list (local journalists), another a geo-search for tweets near a location. This enables analysts to handle the firehose of information in crises. We saw its utility in the Ukraine 2022 case, where analysts had columns for key cities to watch incoming reports. Training Use: We will use TweetDeck in an exercise to monitor a simulated breaking event and practice filtering signal from noise. You’ll learn to set up search operators (e.g. lang:en or near:“Kyiv”) and verify content. Policy: TweetDeck itself is just a UI for Twitter – using it is equivalent to using Twitter, which is generally allowed on unclassified government networks (though subject to local policy). DoD Approved?: There’s no formal “approval” needed to use TweetDeck on NIPRNet, but caution: analysts should use official or alias accounts, not personal accounts, when logged in, and adhere to record-keeping rules if intelligence information is collected. Also, since August 2023 TweetDeck (now “X Pro”) requires a paid API key for full use – units must handle licensing or use alternatives. For illustration, TweetDeck is fine (we have a training developer account for it). On classified systems, obviously live Twitter is not available, so this is strictly an unclassified domain tool. We mark it as Unclassified/Approved for use (with adherence to social media policy). Keep in mind OPSEC: even just following certain handles could tip off adversaries, so analysts use stealth settings (never post or like content from a military-affiliated account via TweetDeck).
	•	Wayback Machine (Internet Archive): A public web archive that stores snapshots of websites over time. Capability: The Wayback Machine is essentially a time machine for the internet – it allows us to retrieve deleted or changed web pages. This is crucial in OSINT because adversaries often delete incriminating content once they realize its intelligence value. For example, if a militant group’s website posted a manifesto last week and then removed it, the Archive might have saved it. Usage in Training: We will practice using archive.org to find an old version of a threat actor’s blog that reveals their earlier statements (which might contain exploitable info). We’ll also use it to illustrate how to get around “404 not found” by checking if the page was archived. Policy & Approval: The Wayback Machine is simply a website – using it is generally benign. It’s allowed on NIPRNet (no special clearance needed). One caution: archived content might include sensitive personal data or even malware if the original had it; treat downloads with the same security scans. Also, some foreign hostile sites might be archived – accessing them via Wayback is safer than visiting live hostile sites (since it’s an image of past content), but if in doubt, coordinate with IT security. From a data policy perspective, archive.org is a public source. According to OSINT best practices, analysts should prefer archived links in their reports to ensure the source can be revisited by others (which supports VAULTIS principles of Visible & Accessible data). No specific DoD approval required; it’s an illustrative tool that is effectively free game for all OSINT practitioners. (Note: Do not confuse “approved” with “secure” – always use official devices to access it to avoid infecting anything if you stumble on archived malware.)
	•	Geofeedia (Geo-social media aggregator): A location-based social media monitoring platform. Capability: Geofeedia (and similar tools) aggregate posts from various social media platforms based on geotags, in real time. For instance, an analyst could draw a shape on a map (say, around Marawi City) and see all publicly posted photos, tweets, etc. from that area during a selected timeframe. This is incredibly useful for situational awareness in crises or for event security. In a protest scenario, such a tool can show you everything people on the ground are sharing. Training Applicability: While Geofeedia itself is a proprietary platform (and its access to certain APIs has been curtailed in recent years), we discuss the concept and will demo a similar capability using available APIs or recorded data. The idea is to get analysts thinking spatially – e.g. during the MH17 case, if such a tool had been applied, one could’ve immediately pulled up all social posts from Donetsk that day and perhaps caught the early Buk sightings even faster. Policy/Status: DoD/IC Approved?: After controversies (Geofeedia was used by law enforcement to monitor protests, raising privacy concerns), social media companies restricted third-party access. DoD does not currently have Geofeedia as a sanctioned tool. However, alternative approved tools like Dataminr (which is used under contract by DoD and DHS) provide similar geo-social alerts. For our purposes, Geofeedia is illustrative only – we won’t access live data but use historical data to simulate its function. If an intelligence unit wanted this capability, they’d go through an approval and contract process (and ensure use is in line with privacy guidelines). Analysts must remember that even though posts are public, systematically collecting geo-tagged personal posts can trigger privacy/oversight rules, especially if U.S. persons are involved. Thus, any such tool must be used under proper authority. In training, we emphasize policy: you can observe social media like a public square, but once you start collecting and databasing posts, you’re potentially doing intelligence collection that might need higher-level permission if it involves U.S. persons. In coalition contexts, tools like this would need sharing agreements (some partners might not allow their data to be pooled this way).
	•	Google (Advanced Search Operators): Not a tool per se, but a technique – using Google and other search engines with advanced operators (Google Dorks). We covered this in TTPs, but to list in logistics: Capability: Enables finding needles in haystacks – e.g. using site:mil to search only military domains, or filetype:pdf "fragmentation grenade" to find PDF files containing certain text (maybe arms smuggling reports). Training: We have a “Google hacking” cheat sheet; analysts will practice queries to discover, say, an open directory of rebel group photos that wasn’t obvious via normal browsing. Policy: Obviously Google is accessible to all. What to watch is what you search for. Don’t type classified info or someone’s personal SSN into Google – that would be a security incident. Also, certain dorks might inadvertently access something not meant to be public (e.g. a misconfigured server with personal data). If that happens, per policy, stop and report to security – don’t exploit it further on your own. Google Dorking is approved and encouraged as an OSINT skill (the DoD even lists common dorking techniques in OSINT training materials). Just keep good judgment; if you find yourself accessing non-public data due to a dork, treat it as sensitive and get guidance. We tag Google and search-engine use as standard issue tools – no procurement needed, just knowledge.

Additionally, we maintain an OSINT Tools Handbook (2025) (based on NATO and industry best practices) – each student has a copy in PDF. It includes resources like Whois lookup services, reverse image search engines, translation tools, etc. These are all unclassified tools to assist your collection. If any tool requires a login or API key, ensure you use the project-approved accounts (for instance, we have a dummy Facebook account to use for searching within Facebook – credentials are with the instructor). Do not use personal accounts or information.

Logistics: For practical exercises, all analysts will use the OSINT workstations on the unclassified network (NIPRNet) which are configured with the above tools. Internet access is filtered through our network – if you hit a blocked site that you believe is mission-critical, notify the G-6 to review if an exception can be made (we have a waiver process for certain social sites). All activities on these workstations are logged for oversight (training environment and real world alike – this is to protect you as well, ensuring we have an audit trail that you only accessed authorized data).

We have reference materials available: Joint Publication 2-0, Marine Corps Doctrinal Pub 2, and NATO’s OSINT Handbook are loaded on your tablets for quick lookup of doctrine. The ODNI “Law and Policy in OSINT” one-pager is also provided, summarizing what you can/can’t do (e.g. rules on creating online personas, which we are not doing in this lesson – that ventures into counterintelligence/collection operations rather than passive OSINT).

Classification and Dissemination: All OSINT derived products will be initially marked UNCLASSIFIED//FOR OFFICIAL USE ONLY (or REL NATO, etc., if sharing with coalition) unless we integrate them with classified analysis – then we upgrade classification accordingly. Remember, just because something is public doesn’t always mean it stays unclassified in intel reports; if we confirm it with SIGINT or add analysis revealing capabilities, classification might rise. We will employ the “tearline” approach: sensitive sources (even OSINT tools) will be kept behind a tearline while the actionable info is moved upfront at lowest classification for use ￼. This is both a policy and logistic measure – enabling wider sharing without compromising methods.

Approved Networks: OSINT can be discussed and stored on unclassified systems, but if you must move OSINT findings to a classified brief, sanitize and attribute them properly. Our JIC (Joint Intel Center) has a procedure for that. Within this class, assume all work is on unclass unless told otherwise.

Reporting Formats: We will use the OSINT report format as per ATP 2-22.9 Appendix D (which is akin to an INTREP). Key is to include source citations (with URLs or archive links) in footnotes – this is both to credit sources and to abide by ODNI best practice of transparency in OSINT products ￼. We have an instructive sidebar in the student guide about citation formatting (mirroring the style used in this document with bracketed source numbers). This is not just academic – it builds trust with consumers and lets them retrieve the original info (VAULTIS: Visible and Accessible data).

Finally, any equipment needs: Each student needs a laptop, which is provided. Ensure you have your login credentials and that you’ve completed cybersecurity training (since we will be visiting external sites). If you need access to a site that is blocked, coordinate with the instructor – do not install random software or use personal phones to bypass the system. Our training environment simulates real constraints intentionally.

Command & Signal

Command Structure: OSINT operations will be conducted under the authority of the J-2/G-2 (Senior Intelligence Officer) of the unit. The OSINT team (or individuals tasked with OSINT) reports to the Intel Officer and Collection Manager. Within our training scenario chain, the OSINT Cell Lead is responsible for coordinating all OSINT collection efforts and ensuring they align with the commander’s PIRs. This lead will also be the point of contact with the unit’s Foreign Disclosure Officer (FDO) and SJA (Staff Judge Advocate) for any questions on sharing or legal boundaries – in effect, the OSINT lead must clear any questionable collection or dissemination through those channels (just as we saw in Scenario 3). In a MAGTF, OSINT may be a function within the intel battalion; for this course, assume the “OSINT section” answers to the MAGTF G-2 who provides guidance and prioritization.

Authority and Oversight: The Command has expressly ordered that all OSINT collection must comply with applicable directives. The Intelligence Oversight Officer (often the XO or a designated official in each command) will randomly review OSINT activities for compliance. This is not adversarial – it’s to keep us all safe and within the law. As analysts, if you are unsure about whether you should collect certain info, elevate it up your chain before proceeding. Remember that ethical conduct is commander’s intent: better to miss an intelligence tip than to violate our legal obligations. Command has also emphasized adherence to VAULTIS principles as a matter of policy – particularly, making data Visible and Linked (we will catalog OSINT findings in the intel database with proper metadata tags so others know it exists), ensuring it’s Accessible and Interoperable to those who need it (e.g. share with coalition on releasable networks when cleared), and keeping it Trustworthy and Secure (don’t manipulate OSINT data without attribution, and protect any sensitive source details).

In practice, this means the command wants OSINT integrated into the Common Operational Picture and intelligence summaries. The OSINT officer will brief in each daily CUB (Commanders Update Brief) alongside SIGINT, etc., to ensure open-source indicators are included. Command will evaluate OSINT contribution in after-action reviews, so it is a fully recognized part of the intel effort.

Signal (Communication Plan): OSINT findings will be disseminated via established intel channels. For this exercise, use the Intel SharePoint portal for posting OSINT reports (unclassified) and the secure chat (e.g. Mattermost or mIRC channel “OSINT Cell”) for time-sensitive tips. If urgent, OSINT analysts can reach the Command Center via the J-2 on SIPR voice or our JIC’s hotline. However, do not discuss OSINT finds over insecure comms that haven’t been approved – e.g. don’t call the coalition liaison on your personal cell about a sensitive OSINT find; use the official channels (we have a REL NATO chat for that if needed).

We have set up a dedicated OSINT HF radio call sign (for field units) as “OpenEye” – front-line units can request OSINT support by asking OpenEye over the net (this is more relevant in a tactical scenario where, say, a platoon might ask if any social media or news is reporting on the village they’re about to enter). In our training scenario, we will simulate such requests.

All personnel should know the “OSINT reachback” contacts: If you can’t find something in the field, you can request support from the Theater OSINT Center (TOC) via SIPR email. That TOC is manned 24/7 by intel specialists who have broader database access. Use format: “OSINT RFI:” in the subject and include as much detail as possible. For example, “OSINT RFI: Need local media reporting on Route Blue traffic last 24h.” They will reply through secure means. This reachback mechanism ensures no one is solely reliant on their own tools forward – you have a bench of experts to help, per JP 2-0 guidance on federated intelligence.

Succession and Redundancy: If the OSINT Cell lead becomes unavailable, the deputy (or Collection Manager if no deputy) assumes control. Likewise, if our primary OSINT systems go down (e.g. internet outage), we have contingency in place – the S-2 will coordinate with signal to possibly use a commercial internet dongle under proper monitoring, or leverage coalition networks if they’re up. The command has arranged that if all else fails, higher HQ will fax important open-source updates to us (yes, a fax – it’s a fail-safe for critical alerts like breaking news of ceasefire). This is mentioned to illustrate that OSINT, while mostly digital, is important enough that command has layered communication methods to get it through.

Coordination with IO and Public Affairs: OSINT often overlaps with Information Operations and PA. Command requires that our OSINT Cell deconflict with the Information Operations cell (J-39) especially if we plan any active engagements (which we generally are not in OSINT – that would be IO’s realm). For example, if IO is running a deception on social media, we need to know so we don’t accidentally treat our own deception as real OSINT. Similarly, anything we find that might hit the news, we share with Public Affairs so they aren’t blindsided. There’s a standing order: if OSINT discovers adversary propaganda or misinformation trending, immediately inform the IO officer. That way the command’s messaging can respond. This highlights that OSINT is not done in a vacuum – it ties into the broader information picture.

Reports to Higher: The command will include an OSINT summary in daily intel reports to the Combatant Commander and the Joint OSINT Coordination Center (if established). We use the ODNI OSINT best practices in those summaries, e.g. clearly separating fact from analysis and providing our source list ￼. This ensures higher-ups appreciate our contribution and can cross-reference it with other intel.

In sum, the Command expects OSINT to be a force multiplier and an integrated part of the C2 (command and control) and intelligence process. By following the above C2 structure, communications plan, and ethical guidelines, we ensure OSINT support is reliable and ready. As the Commander might put it in the OPORD brief: “Eyes and ears open, team – use all sources available, but do it the right way. The world is watching as much as we are watching the world.” All signals are green – execute the plan and keep information flowing.

End of OPORD – Q&A and Clarifications: (At this time, instructors would take any questions about roles, tool access, or scenario specifics. Ensure everyone knows who to call for what, and then we will move into the practical application phase of the masterclass.)